{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn import (\n",
    "    cluster, decomposition, ensemble, manifold, \n",
    "    random_projection, preprocessing)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../sample_df.csv')df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text.values\n",
    "y = df.likes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=200, stop_words='english', analyzer='word', strip_accents='ascii', sublinear_tf = True)\n",
    "vect = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000', '10', 'actually', 'ago', 'agree', 'alaska', 'america',\n",
       "       'american', 'americans', 'article', 'away', 'bad', 'based',\n",
       "       'believe', 'best', 'better', 'big', 'business', 'called', 'canada',\n",
       "       'canadian', 'canadians', 'care', 'case', 'change', 'children',\n",
       "       'church', 'city', 'clinton', 'com', 'come', 'comment', 'comments',\n",
       "       'control', 'cost', 'country', 'course', 'day', 'deal', 'did',\n",
       "       'didn', 'different', 'does', 'doesn', 'doing', 'don', 'election',\n",
       "       'end', 'fact', 'family', 'far', 'federal', 'feel', 'free',\n",
       "       'getting', 'given', 'god', 'going', 'good', 'got', 'government',\n",
       "       'great', 'guy', 'hard', 'having', 'health', 'help', 'high',\n",
       "       'hillary', 'history', 'home', 'hope', 'house', 'http', 'https',\n",
       "       'human', 'idea', 'income', 'instead', 'isn', 'issue', 'job',\n",
       "       'jobs', 'just', 'kids', 'know', 'law', 'left', 'let', 'liberal',\n",
       "       'liberals', 'life', 'like', 'line', 'little', 'live', 'll', 'long',\n",
       "       'look', 'lot', 'love', 'make', 'makes', 'making', 'man', 'matter',\n",
       "       'maybe', 'mean', 'means', 'media', 'men', 'million', 'money', 'mr',\n",
       "       'need', 'needs', 'new', 'news', 'non', 'obama', 'office', 'oh',\n",
       "       'oil', 'old', 'paid', 'party', 'past', 'pay', 'people', 'person',\n",
       "       'place', 'point', 'police', 'political', 'poor', 'post', 'power',\n",
       "       'president', 'pretty', 'probably', 'problem', 'public', 'question',\n",
       "       'read', 'real', 'really', 'reason', 'republican', 'right',\n",
       "       'rights', 'run', 'said', 'say', 'saying', 'says', 'school',\n",
       "       'sense', 'simply', 'start', 'state', 'states', 'stop', 'story',\n",
       "       'support', 'sure', 'tax', 'taxes', 'tell', 'thing', 'things',\n",
       "       'think', 'thought', 'time', 'times', 'today', 'trudeau', 'true',\n",
       "       'trump', 'try', 'trying', 'understand', 'use', 'used', 'using',\n",
       "       've', 'vote', 'want', 'war', 'way', 'white', 'women', 'won',\n",
       "       'work', 'working', 'world', 'wrong', 'www', 'year', 'years', 'yes'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = vectorizer.get_feature_names()\n",
    "np.unique(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans()\n",
    "kmeans.fit(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_cluster = kmeans.transform(vect).argmin(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'articles_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-41db9790f85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massigned_cluster\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtopics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticles_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'section_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmost_common\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cluster {i}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'articles_df' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(kmeans.n_clusters):\n",
    "    cluster = np.arange(0, vect.shape[0])[assigned_cluster==i]\n",
    "    topics = articles_df.loc[cluster].dropna()['section_name']\n",
    "    most_common = Counter(topics).most_common()\n",
    "    print(f\"Cluster {i}:\")\n",
    "    for j in range (len(most_common)):\n",
    "        print(f\"     {most_common[j][0]} ({most_common[j][1]} articles)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer(max_df = 0.85, stop_words='english', min_df=2, max_features=1000)\n",
    "# X = vectorizer.fit_transform(X)\n",
    "# X = (X.todense())\n",
    "# X.shape\n",
    "# tokens = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss = preprocessing.StandardScaler()\n",
    "# X = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbs = DBSCAN(eps = 1.5, min_samples= 2, n_jobs = -1)\n",
    "# dbs.fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(kmeans.cluster_centers_)\n",
    "# top_centroids = kmeans.cluster_centers_.argsort()[:,-1:-11:-1]\n",
    "# print(\"top features for each cluster with 500 max features:\")\n",
    "# for num, centroid in enumerate(top_centroids):\n",
    "#     print(f\"{num}, {', '.join(features[i] for i in centroid)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_clusters = len(set(kmeans.labels_)) - (1 if -1 in kmeans.labels_ else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbs = DBSCAN(eps = 1.5, min_samples= 2, n_jobs = -1)\n",
    "# dbs.fit(vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = dbs.labels_\n",
    "# n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "# n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
